{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building RAG with Qwen2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# PhoBERT Model Details\n",
    "model_name = \"vinai/phobert-base\"\n",
    "\n",
    "# Initialize PhoBERT tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# PhoBERT Embedding Class\n",
    "class PhoBERTEmbeddings:\n",
    "    def __init__(self, model, tokenizer, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "        self.model = model.to(device)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "\n",
    "    def embed_text(self, text: str) -> torch.Tensor:\n",
    "        \"\"\"Generate embeddings for a given text.\"\"\"\n",
    "        # Tokenize and get model outputs\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "        inputs = {k: v.to(self.device) for k, v in inputs.items()}\n",
    "        outputs = self.model(**inputs)\n",
    "        \n",
    "        # Use mean pooling of the last hidden states\n",
    "        hidden_states = outputs.last_hidden_state  # Shape: [batch_size, seq_length, hidden_dim]\n",
    "        attention_mask = inputs[\"attention_mask\"]\n",
    "        mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size())\n",
    "        sum_embeddings = torch.sum(hidden_states * mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n",
    "        mean_pooled = sum_embeddings / sum_mask\n",
    "        \n",
    "        return mean_pooled.squeeze(0).detach().cpu()\n",
    "\n",
    "    def embed_documents(self, texts: list[str]) -> list[torch.Tensor]:\n",
    "        \"\"\"Generate embeddings for a batch of documents.\"\"\"\n",
    "        return [self.embed_text(text) for text in texts]\n",
    "\n",
    "    def embed_query(self, text: str) -> torch.Tensor:\n",
    "        \"\"\"Generate an embedding for a query.\"\"\"\n",
    "        return self.embed_text(text)\n",
    "\n",
    "# Initialize PhoBERT embeddings\n",
    "phobert_embeddings = PhoBERTEmbeddings(model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Step 1: Clear Chroma database if it exists\n",
    "persist_dir = \"./chroma.db\"\n",
    "import shutil, os\n",
    "if os.path.exists(persist_dir):\n",
    "    shutil.rmtree(persist_dir)\n",
    "\n",
    "# Step 2: Load JSON files and convert to LangChain Documents\n",
    "input_folder = \"Vietnam-Law-rag_json\"\n",
    "documents = []\n",
    "for file_name in os.listdir(input_folder):\n",
    "    if file_name.endswith(\".json\"):\n",
    "        file_path = os.path.join(input_folder, file_name)\n",
    "        base_file_name = os.path.splitext(file_name)[0]\n",
    "        \n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        documents.extend([\n",
    "            Document(\n",
    "                page_content=entry[\"text\"],\n",
    "                metadata={\n",
    "                    \"id\": entry[\"id\"],\n",
    "                    \"article\": entry[\"article\"],\n",
    "                    \"clause\": entry[\"clause\"],\n",
    "                    \"title\": entry[\"title\"],\n",
    "                    \"file_id\": base_file_name\n",
    "                }\n",
    "            )\n",
    "            for entry in data\n",
    "        ])\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents from {input_folder}.\")\n",
    "\n",
    "# Step 3: Create embeddings for documents\n",
    "embedded_documents = [\n",
    "    {\n",
    "        \"embedding\": phobert_embeddings.embed_text(doc.page_content),\n",
    "        \"metadata\": doc.metadata,\n",
    "        \"content\": doc.page_content,\n",
    "    }\n",
    "    for doc in documents\n",
    "]\n",
    "\n",
    "# Step 4: Store in Chroma Vector Store\n",
    "vectorstore = Chroma.from_embeddings(\n",
    "    embeddings=[doc[\"embedding\"] for doc in embedded_documents],\n",
    "    documents=[doc[\"content\"] for doc in embedded_documents],\n",
    "    metadatas=[doc[\"metadata\"] for doc in embedded_documents],\n",
    "    persist_directory=persist_dir\n",
    ")\n",
    "\n",
    "vectorstore.persist()\n",
    "print(\"Chroma database created and saved at:\", persist_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test query\n",
    "## RAG database builded on cloud servers, fetch them then run the below cell\n",
    "\n",
    "The aim is to optimize the returned data after the query search before push into the LLM Models, below here use Qwen2.5 for example.\n",
    "\n",
    "Just download the chroma.db, then symlink or put them in the current working git folder, then run the second cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CELL 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27915/1845614436.py:14: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroma database loaded.\n",
      "Model and pipeline initialized.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from langchain.vectorstores import Chroma\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Step 1: Load the Chroma Database\n",
    "persist_dir = \"./chroma.db\"\n",
    "\n",
    "# Initialize the embedding function\n",
    "embeddings_model = HuggingFaceEmbeddings()\n",
    "\n",
    "# Load the Chroma database with the embedding function\n",
    "vectorstore = Chroma(\n",
    "    persist_directory=persist_dir,\n",
    "    embedding_function=embeddings_model\n",
    ")\n",
    "\n",
    "print(\"Chroma database loaded.\")\n",
    "\n",
    "# Step 2: Load Qwen Model\n",
    "model_id = \"Qwen/Qwen2.5-0.5B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "\n",
    "# Step 3: Set Device for GPU/CPU\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# Step 4: Create a Text-Generation Pipeline with GPU/CPU\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=100,\n",
    "    device=device,\n",
    "    clean_up_tokenization_spaces=True\n",
    ")\n",
    "\n",
    "# Wrap the pipeline for LangChain\n",
    "hf = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "print(\"Model and pipeline initialized.\")\n",
    "\n",
    "# Move model to CPU to release GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "model.to(\"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CELL 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Trẻ em bị bỏ rơi;\n",
      "\n",
      "Trẻ em.\n",
      "\n",
      "Trạm y tế;\n",
      "\n",
      "Quản trị rủi ro;\n",
      "\n",
      "Trẻ em mồ côi cả cha và mẹ;\n",
      "\n",
      "Trẻ em bị mua bán;\n",
      "\n",
      "Tạm giữ tàu biển;\n",
      "\n",
      "Cơ quan quản lý nhà nước về trẻ em;\n",
      "\n",
      "Cơ quan quản lý nhà nước về trẻ em;\n",
      "\n",
      "Cơ quan quản lý nhà nước về trẻ em;\n",
      "\n",
      "Cơ quan quản lý nhà nước về trẻ em;\n",
      "\n",
      "Cơ quan quản lý nhà nước về trẻ em;\n",
      "\n",
      "Cướp biển, cướp có vũ trang;\n",
      "\n",
      "Quê quán.\n",
      "\n",
      "Cơ sở y tế;\n",
      "\n",
      "Cơ sở y tế.\n",
      "\n",
      "Cơ sở y tế.\n",
      "\n",
      "Quê quán;\n",
      "\n",
      "Quê quán;\n",
      "\n",
      "Quê quán;\n",
      "\n",
      "Có giáo lý, giáo luật, lễ nghi;\n",
      "\n",
      "Quản chế;\n",
      "\n",
      "Hỗ trợ y tế;\n",
      "\n",
      "Biện pháp sơ cứu về y tế;\n",
      "\n",
      "Y tế, văn hóa, giáo dục;\n",
      "\n",
      "Cột cây số;\n",
      "\n",
      "Trẻ em bị bóc lột;\n",
      "\n",
      "Viện pháp y quốc gia thuộc Bộ Y tế;\n",
      "\n",
      "Trẻ em vi phạm pháp luật;\n",
      "\n",
      "Chi viện trợ.\n",
      "\n",
      "Có giáo lý, giáo luật;\n",
      "\n",
      "Diễn biến của quá trình hòa giải;\n",
      "\n",
      "Hồ sơ mời thầu.\n",
      "\n",
      "Hỗ trợ tâm lý;\n",
      "\n",
      "Cơ sở dữ liệu về con người;\n",
      "\n",
      "Tên tàu biển;\n",
      "\n",
      "Trẻ em của cơ sở giáo dục mầm non;\n",
      "\n",
      "Trẻ em nghiện ma túy;\n",
      "\n",
      "Cọc mốc chỉ giới;\n",
      "\n",
      "Cơ sở giáo dục.\n",
      "\n",
      "Chi viện trợ;\n",
      "\n",
      "Vũ trang.\n",
      "\n",
      "Trẻ em khuyết tật;\n",
      "\n",
      "Biên bản giao người bị quản chế;\n",
      "\n",
      "Sĩ quan dự bị.\n",
      "\n",
      "Giả danh Dân quân tự vệ.\n",
      "\n",
      "Y sỹ;\n",
      "\n",
      "Dịch vụ môi giới tiền tệ.\n",
      "\n",
      "Qua biên giới;\n",
      "\n",
      "Qua biên giới;\n",
      "\n",
      "Question: Trẻ em là gì\n",
      "Helpful Answer: Trẻ em là trẻ em bị bỏ rơi, trẻ em mồ côi cả cha và mẹ, trẻ em bị mua bán, trẻ em bị bóc lột, trẻ em vi phạm pháp luật, trẻ em nghiện ma túy, trẻ em khuyết tật, trẻ em bị bỏ rơi, trẻ em bị bóc lột, trẻ em bị mua bán, trẻ em bị bóc lột, trẻ em bị bóc lột, trẻ em bị bóc\n",
      "Source Documents:\n",
      "Metadata: {'article': 'Điều 10', 'clause': '1b', 'file_id': 'Luật-102-2016-QH13', 'id': 'Điều 10.1b', 'title': 'Trẻ em có hoàn cảnh đặc biệt'}\n",
      "Content: Trẻ em bị bỏ rơi;\n",
      "\n",
      "Metadata: {'article': 'Điều 7', 'clause': '3', 'file_id': 'Luật-11-2017-QH14', 'id': 'Điều 7.3', 'title': 'Người được trợ giúp pháp lý'}\n",
      "Content: Trẻ em.\n",
      "\n",
      "Metadata: {'article': 'Điều 48', 'clause': '1g', 'file_id': 'Luật-15-2023-QH15', 'id': 'Điều 48.1g', 'title': 'Hình thức tổ chức của cơ sở khám bệnh, chữa bệnh'}\n",
      "Content: Trạm y tế;\n",
      "\n",
      "Metadata: {'article': 'Điều 90', 'clause': '1c', 'file_id': 'Luật-08-2022-QH15', 'id': 'Điều 90.1c', 'title': 'Hoạt động thuê ngoài'}\n",
      "Content: Quản trị rủi ro;\n",
      "\n",
      "Metadata: {'article': 'Điều 10', 'clause': '1a', 'file_id': 'Luật-102-2016-QH13', 'id': 'Điều 10.1a', 'title': 'Trẻ em có hoàn cảnh đặc biệt'}\n",
      "Content: Trẻ em mồ côi cả cha và mẹ;\n",
      "\n",
      "Metadata: {'article': 'Điều 10', 'clause': '1m', 'file_id': 'Luật-102-2016-QH13', 'id': 'Điều 10.1m', 'title': 'Trẻ em có hoàn cảnh đặc biệt'}\n",
      "Content: Trẻ em bị mua bán;\n",
      "\n",
      "Metadata: {'article': 'Điều 11', 'clause': '2c', 'file_id': 'Bộ luật-95-2015-QH13', 'id': 'Điều 11.2c', 'title': 'Thanh tra hàng hải'}\n",
      "Content: Tạm giữ tàu biển;\n",
      "\n",
      "Metadata: {'article': 'Điều 10', 'clause': '2c', 'file_id': 'Luật-52-2014-QH13', 'id': 'Điều 10.2c', 'title': 'Người có quyền yêu cầu hủy việc kết hôn trái pháp luật'}\n",
      "Content: Cơ quan quản lý nhà nước về trẻ em;\n",
      "\n",
      "Metadata: {'article': 'Điều 84', 'clause': '5c', 'file_id': 'Luật-52-2014-QH13', 'id': 'Điều 84.5c', 'title': 'Thay đổi người trực tiếp nuôi con sau khi ly hôn'}\n",
      "Content: Cơ quan quản lý nhà nước về trẻ em;\n",
      "\n",
      "Metadata: {'article': 'Điều 102', 'clause': '3c', 'file_id': 'Luật-52-2014-QH13', 'id': 'Điều 102.3c', 'title': 'Người có quyền yêu cầu xác định cha, mẹ, con'}\n",
      "Content: Cơ quan quản lý nhà nước về trẻ em;\n",
      "\n",
      "Metadata: {'article': 'Điều 86', 'clause': '2c', 'file_id': 'Luật-52-2014-QH13', 'id': 'Điều 86.2c', 'title': 'Người có quyền yêu cầu Tòa án hạn chế quyền của cha, mẹ đối với con chưa thành niên'}\n",
      "Content: Cơ quan quản lý nhà nước về trẻ em;\n",
      "\n",
      "Metadata: {'article': 'Điều 119', 'clause': '2c', 'file_id': 'Luật-52-2014-QH13', 'id': 'Điều 119.2c', 'title': 'Người có quyền yêu cầu thực hiện nghĩa vụ cấp dưỡng'}\n",
      "Content: Cơ quan quản lý nhà nước về trẻ em;\n",
      "\n",
      "Metadata: {'article': 'Điều 37', 'clause': '8', 'file_id': 'Luật-18-2012-QH13', 'id': 'Điều 37.8', 'title': 'Quy định cấm trong vùng đặc quyền kinh tế và thềm lục địa Việt Nam'}\n",
      "Content: Cướp biển, cướp có vũ trang;\n",
      "\n",
      "Metadata: {'article': 'Điều 9', 'clause': '8', 'file_id': 'Luật-26-2023-QH15', 'id': 'Điều 9.8', 'title': 'Thông tin trong Cơ sở dữ liệu quốc gia về dân cư'}\n",
      "Content: Quê quán.\n",
      "\n",
      "Metadata: {'article': 'Điều 11', 'clause': '1a', 'file_id': 'Luật-09-2012-QH13', 'id': 'Điều 11.1a', 'title': 'Địa điểm cấm hút thuốc lá hoàn toàn'}\n",
      "Content: Cơ sở y tế;\n",
      "\n",
      "Metadata: {'article': 'Điều 10', 'clause': '1', 'file_id': 'Luật-44-2019-QH14', 'id': 'Điều 10.1', 'title': 'Địa điểm không uống rượu, bia'}\n",
      "Content: Cơ sở y tế.\n",
      "\n",
      "Metadata: {'article': 'Điều 19', 'clause': '1', 'file_id': 'Luật-44-2019-QH14', 'id': 'Điều 19.1', 'title': 'Địa điểm không bán rượu, bia'}\n",
      "Content: Cơ sở y tế.\n",
      "\n",
      "Metadata: {'article': 'Điều 37', 'clause': '1đ', 'file_id': 'Luật-68-2020-QH14', 'id': 'Điều 37.1đ', 'title': 'Sửa đổi, bổ sung, bãi bỏ một số điều của các luật có liên quan đến quản lý cư trú'}\n",
      "Content: Quê quán;\n",
      "\n",
      "Metadata: {'article': 'Điều 9', 'clause': '1đ', 'file_id': 'Luật-59-2014-QH13', 'id': 'Điều 9.1đ', 'title': 'Thông tin về công dân được thu thập, cập nhật vào Cơ sở dữ liệu quốc gia về dân cư'}\n",
      "Content: Quê quán;\n",
      "\n",
      "Metadata: {'article': 'Điều 30', 'clause': '3k', 'file_id': 'Luật-26-2023-QH15', 'id': 'Điều 30.3k', 'title': 'Giấy chứng nhận căn cước và quản lý về căn cước đối với người gốc Việt Nam chưa xác định được quốc tịch được cấp giấy chứng nhận căn cước'}\n",
      "Content: Quê quán;\n",
      "\n",
      "Metadata: {'article': 'Điều 18', 'clause': '1', 'file_id': 'Luật-02-2016-QH14', 'id': 'Điều 18.1', 'title': 'Điều kiện để tổ chức được cấp chứng nhận đăng ký hoạt động tôn giáo'}\n",
      "Content: Có giáo lý, giáo luật, lễ nghi;\n",
      "\n",
      "Metadata: {'article': 'Điều 32', 'clause': '2c', 'file_id': 'Bộ luật-100-2015-QH13', 'id': 'Điều 32.2c', 'title': 'Các hình phạt đối với người phạm tội'}\n",
      "Content: Quản chế;\n",
      "\n",
      "Metadata: {'article': 'Điều 32', 'clause': '1b', 'file_id': 'Luật-66-2011-QH12 ', 'id': 'Điều 32.1b', 'title': 'Đối tượng và chế độ hỗ trợ'}\n",
      "Content: Hỗ trợ y tế;\n",
      "\n",
      "Metadata: {'article': 'Điều 29', 'clause': '3h', 'file_id': 'Luật-06-2007-QH12', 'id': 'Điều 29.3h', 'title': 'Phiếu an toàn hóa chất'}\n",
      "Content: Biện pháp sơ cứu về y tế;\n",
      "\n",
      "Metadata: {'article': 'Điều 8', 'clause': '5a', 'file_id': 'Luật-39-2019-QH14', 'id': 'Điều 8.5a', 'title': 'Tiêu chí phân loại dự án nhóm A'}\n",
      "Content: Y tế, văn hóa, giáo dục;\n",
      "\n",
      "Metadata: {'article': 'Điều 45', 'clause': '1đ', 'file_id': 'Luật-23-2008-QH12', 'id': 'Điều 45.1đ', 'title': 'Công trình báo hiệu đường bộ'}\n",
      "Content: Cột cây số;\n",
      "\n",
      "Metadata: {'article': 'Điều 10', 'clause': '1k', 'file_id': 'Luật-102-2016-QH13', 'id': 'Điều 10.1k', 'title': 'Trẻ em có hoàn cảnh đặc biệt'}\n",
      "Content: Trẻ em bị bóc lột;\n",
      "\n",
      "Metadata: {'article': 'Điều 12', 'clause': '2a', 'file_id': 'Luật-13-2012-QH13', 'id': 'Điều 12.2a', 'title': 'Tổ chức giám định tư pháp công lập'}\n",
      "Content: Viện pháp y quốc gia thuộc Bộ Y tế;\n",
      "\n",
      "Metadata: {'article': 'Điều 10', 'clause': '1e', 'file_id': 'Luật-102-2016-QH13', 'id': 'Điều 10.1e', 'title': 'Trẻ em có hoàn cảnh đặc biệt'}\n",
      "Content: Trẻ em vi phạm pháp luật;\n",
      "\n",
      "Metadata: {'article': 'Điều 36', 'clause': '5', 'file_id': 'Luật-83-2015-QH13', 'id': 'Điều 36.5', 'title': 'Nhiệm vụ chi của ngân sách trung ương'}\n",
      "Content: Chi viện trợ.\n",
      "\n",
      "Metadata: {'article': 'Điều 16', 'clause': '2a', 'file_id': 'Luật-02-2016-QH14', 'id': 'Điều 16.2a', 'title': 'Điều kiện đăng ký sinh hoạt tôn giáo tập trung'}\n",
      "Content: Có giáo lý, giáo luật;\n",
      "\n",
      "Metadata: {'article': 'Điều 24', 'clause': '2d', 'file_id': 'Luật-35-2013-QH13', 'id': 'Điều 24.2d', 'title': 'Hòa giải thành'}\n",
      "Content: Diễn biến của quá trình hòa giải;\n",
      "\n",
      "Metadata: {'article': 'Điều 87', 'clause': '1', 'file_id': 'Luật-64-2020-QH14', 'id': 'Điều 87.1', 'title': 'Nội dung giám sát của cơ quan quản lý nhà nước về đầu tư theo phương thức PPP'}\n",
      "Content: Hồ sơ mời thầu.\n",
      "\n",
      "Metadata: {'article': 'Điều 32', 'clause': '1c', 'file_id': 'Luật-66-2011-QH12 ', 'id': 'Điều 32.1c', 'title': 'Đối tượng và chế độ hỗ trợ'}\n",
      "Content: Hỗ trợ tâm lý;\n",
      "\n",
      "Metadata: {'article': 'Điều 36', 'clause': '3a', 'file_id': 'Luật-89-2015-QH13', 'id': 'Điều 36.3a', 'title': 'Sử dụng dữ liệu hành chính cho hoạt động thống kê nhà nước'}\n",
      "Content: Cơ sở dữ liệu về con người;\n",
      "\n",
      "Metadata: {'article': 'Điều 160', 'clause': '1d', 'file_id': 'Bộ luật-95-2015-QH13', 'id': 'Điều 160.1d', 'title': 'Nội dung của vận đơn'}\n",
      "Content: Tên tàu biển;\n",
      "\n",
      "Metadata: {'article': 'Điều 80', 'clause': '1', 'file_id': 'Luật-43-2019-QH14', 'id': 'Điều 80.1', 'title': 'Người học'}\n",
      "Content: Trẻ em của cơ sở giáo dục mầm non;\n",
      "\n",
      "Metadata: {'article': 'Điều 10', 'clause': '1g', 'file_id': 'Luật-102-2016-QH13', 'id': 'Điều 10.1g', 'title': 'Trẻ em có hoàn cảnh đặc biệt'}\n",
      "Content: Trẻ em nghiện ma túy;\n",
      "\n",
      "Metadata: {'article': 'Điều 19', 'clause': '1đ', 'file_id': 'Luật-06-2017-QH14', 'id': 'Điều 19.1đ', 'title': 'Hệ thống báo hiệu cố định trên đường sắt'}\n",
      "Content: Cọc mốc chỉ giới;\n",
      "\n",
      "Metadata: {'article': 'Điều 19', 'clause': '2', 'file_id': 'Luật-44-2019-QH14', 'id': 'Điều 19.2', 'title': 'Địa điểm không bán rượu, bia'}\n",
      "Content: Cơ sở giáo dục.\n",
      "\n",
      "Metadata: {'article': 'Điều 5', 'clause': '2đ', 'file_id': 'Luật-83-2015-QH13', 'id': 'Điều 5.2đ', 'title': 'Phạm vi ngân sách nhà nước'}\n",
      "Content: Chi viện trợ;\n",
      "\n",
      "Metadata: {'article': 'Điều 20', 'clause': '1g', 'file_id': 'Luật-66-2020-QH14', 'id': 'Điều 20.1g', 'title': 'Biện pháp quản lý, bảo vệ biên giới quốc gia'}\n",
      "Content: Vũ trang.\n",
      "\n",
      "Metadata: {'article': 'Điều 10', 'clause': '1d', 'file_id': 'Luật-102-2016-QH13', 'id': 'Điều 10.1d', 'title': 'Trẻ em có hoàn cảnh đặc biệt'}\n",
      "Content: Trẻ em khuyết tật;\n",
      "\n",
      "Metadata: {'article': 'Điều 112', 'clause': '3d', 'file_id': 'Luật-41-2019-QH14', 'id': 'Điều 112.3d', 'title': 'Thủ tục thi hành án phạt quản chế'}\n",
      "Content: Biên bản giao người bị quản chế;\n",
      "\n",
      "Metadata: {'article': 'Điều 5', 'clause': '5', 'file_id': 'Luật-16-1999-QH10', 'id': 'Điều 5.5', 'title': 'Nguồn bổ sung sĩ quan tại ngũ'}\n",
      "Content: Sĩ quan dự bị.\n",
      "\n",
      "Metadata: {'article': 'Điều 14', 'clause': '3', 'file_id': 'Luật-48-2019-QH14', 'id': 'Điều 14.3', 'title': 'Các hành vi bị nghiêm cấm về Dân quân tự vệ'}\n",
      "Content: Giả danh Dân quân tự vệ.\n",
      "\n",
      "Metadata: {'article': 'Điều 26', 'clause': '1b', 'file_id': 'Luật-15-2023-QH15', 'id': 'Điều 26.1b', 'title': 'Chức danh chuyên môn phải có giấy phép hành nghề'}\n",
      "Content: Y sỹ;\n",
      "\n",
      "Metadata: {'article': 'Điều 107', 'clause': '4', 'file_id': 'Luật-47-2010-QH12', 'id': 'Điều 107.4', 'title': 'Các hoạt động kinh doanh khác của ngân hàng thương mại'}\n",
      "Content: Dịch vụ môi giới tiền tệ.\n",
      "\n",
      "Metadata: {'article': 'Điều 1', 'clause': '2e', 'file_id': 'Luật-12-2017-QH14', 'id': 'Điều 1.2e', 'title': 'Sửa đổi, bổ sung, bãi bỏ một số điều của Bộ luật Hình sự số 100/2015/QH13'}\n",
      "Content: Qua biên giới;\n",
      "\n",
      "Metadata: {'article': 'Điều 1', 'clause': '68g', 'file_id': 'Luật-12-2017-QH14', 'id': 'Điều 1.68g', 'title': 'Sửa đổi, bổ sung, bãi bỏ một số điều của Bộ luật Hình sự số 100/2015/QH13'}\n",
      "Content: Qua biên giới;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Move model to GPU\n",
    "torch.cuda.empty_cache()\n",
    "model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Increase retrieval limit\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 50})\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=hf,\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# Query and retrieval\n",
    "query = \"Trẻ em là gì\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "# Print the Result\n",
    "print(\"Answer:\", result[\"result\"])\n",
    "\n",
    "# Print the Source Documents\n",
    "print(\"Source Documents:\")\n",
    "for doc in result[\"source_documents\"]:\n",
    "    print(f\"Metadata: {doc.metadata}\")\n",
    "    print(f\"Content: {doc.page_content}\\n\")\n",
    "\n",
    "# Move model to CPU to release GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "model.to(\"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CELL 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27915/981992937.py:15: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  results = retriever.get_relevant_documents(query)\n",
      "/tmp/ipykernel_27915/981992937.py:53: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result_from_llm = hf(input_to_llm)  # Assuming 'hf' is your model callable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No relevant documents retrieved or filtered out.\n",
      "Input to LLM: Answer: Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
      "LLM Output: Answer: Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.  Question: What is the name of the person who is the only one who is not a member of the group?  Context:  The group's name was changed to the \"New People's Republic of China\" in 1949, and the name of the leader was changed to Mao Zedong. Mao was the only one who was not a member of the group. Mao was the only one who was the only one who was not a member of the group. Mao was the\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from langchain.chains import RetrievalQA\n",
    "import torch\n",
    "\n",
    "# Move model to GPU\n",
    "torch.cuda.empty_cache()\n",
    "model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Increase retrieval limit\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 250})\n",
    "\n",
    "# Define a custom retriever function that intercepts and modifies the results\n",
    "def custom_retriever(query, k=300):\n",
    "    # Retrieve relevant documents from the retriever\n",
    "    results = retriever.get_relevant_documents(query)\n",
    "    \n",
    "    modified_documents = []\n",
    "    \n",
    "    for doc in results:\n",
    "        # Example of cleaning content: Removing unwanted words or patterns (adjust regex as needed)\n",
    "        cleaned_content = re.sub(r\"unwanted_pattern\", \"\", doc.page_content)\n",
    "        \n",
    "        # Ensure that the content is relevant to the query (optional: further filtering logic)\n",
    "        if 'thời hạn' in cleaned_content.lower():  # Assuming query context involves time limits like 'thời hạn'\n",
    "            modified_doc = {\n",
    "                \"metadata\": doc.metadata,\n",
    "                \"page_content\": cleaned_content,\n",
    "            }\n",
    "            modified_documents.append(modified_doc)\n",
    "    \n",
    "    return modified_documents\n",
    "\n",
    "# Define the instruction for the model\n",
    "instruction = \"Answer: Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\"\n",
    "\n",
    "# Use the custom retriever to retrieve and modify documents\n",
    "query = \"Trẻ em là gì\"\n",
    "retrieved_docs = custom_retriever(query)\n",
    "\n",
    "# Debug: Check if any documents are retrieved and modified\n",
    "if not retrieved_docs:\n",
    "    print(\"No relevant documents retrieved or filtered out.\")\n",
    "else:\n",
    "    print(f\"Retrieved {len(retrieved_docs)} documents.\")\n",
    "\n",
    "# Concatenate the instruction with the retrieved documents\n",
    "input_to_llm = instruction + \" \" + \" \".join([doc[\"page_content\"] for doc in retrieved_docs])\n",
    "\n",
    "# Check the input format before passing to the model\n",
    "print(\"Input to LLM:\", input_to_llm[:500])  # Print the first 500 characters for debugging\n",
    "\n",
    "# Send the modified input to your LLM (e.g., Qwen2.5 model)\n",
    "result_from_llm = hf(input_to_llm)  # Assuming 'hf' is your model callable\n",
    "print(\"LLM Output:\", result_from_llm)\n",
    "\n",
    "# Move model to CPU to release GPU memory\n",
    "torch.cuda.empty_cache()\n",
    "model.to(\"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
